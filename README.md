<div align="center">

# ğŸ§  AI Concepts From Scratch

### *Demystifying Artificial Intelligence, One Algorithm at a Time*

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

*Dive deep into the mathematical elegance and computational beauty of AI algorithms by building them from the ground up.*

[Explore Implementations](#-implemented-concepts) â€¢ [Why From Scratch?](#-why-from-scratch) â€¢ [Get Started](#-getting-started)

---

</div>

## ğŸŒŸ About This Repository

Welcome to a journey through the foundations of artificial intelligence! This repository is a curated collection of AI and deep learning algorithms implemented from first principles. Each implementation peels back the layers of abstraction to reveal the elegant mathematics and clever engineering that power modern AI systems.

> **Philosophy:** *"What I cannot create, I do not understand."* â€“ Richard Feynman

By rebuilding these algorithms without relying on high-level abstractions, we gain intuition that no amount of reading can provide. This is learning by doing, understanding by building.

## ğŸ’¡ Why From Scratch?

<table>
<tr>
<td width="50%">

### ğŸ”¬ **Deep Understanding**
Move beyond surface-level knowledge. When you implement backpropagation by hand or derive attention mechanisms from scratch, the mathematics becomes intuition.

### ğŸ› **Master Debugging**
Know exactly what's happening at every step. Identify bottlenecks, understand edge cases, and optimize with confidence.

</td>
<td width="50%">

### ğŸ¯ **Interview Excellence**
Stand out in technical interviews. Demonstrate not just what algorithms do, but *how* and *why* they work.

### ğŸš€ **Innovation Ready**
Understanding fundamentals is the foundation for innovation. You can't improve what you don't understand.

</td>
</tr>
</table>

---

## ğŸ”¥ Implemented Concepts

### ğŸ¯ Computer Vision & Object Detection

<details open>
<summary><b>Click to explore vision algorithms</b></summary>

<br>

#### ğŸ“ **Intersection over Union (IoU)**
> *The fundamental metric for measuring bounding box overlap*

IoU quantifies how well two bounding boxes alignâ€”essential for evaluating object detection models and implementing NMS.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/IOU_from_scarth/blob/main/IOU%20from%20scratsh.py)**

---

#### ğŸ­ **Non-Maximum Suppression (NMS)**
> *Eliminating redundant detections with elegance*

When a detector fires multiple times for the same object, NMS intelligently selects the best prediction and suppresses the rest.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/IOU_from_scarth/blob/main/Non%20Max%20Suppression.py)**

---

#### ğŸ“Š **Mean Average Precision (mAP)**
> *The gold standard for detection evaluation*

mAP combines precision and recall across all classes and IoU thresholds, providing a single metric that captures model performance comprehensively.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Mean%20Average%20Precision.py)**

---

#### ğŸ¨ **Multi-Class Object Detector**
> *End-to-end detection with ResNet50 backbone*

A complete detection pipeline combining classification and localization. Features dual-head architecture with CrossEntropyLoss for classes and MSELoss for bounding boxes.

**Key Features:**
- ğŸ—ï¸ ResNet50 feature extraction
- ğŸ¯ Multi-class classification head
- ğŸ“¦ Bounding box regression head
- âš¡ Efficient single-stage detection

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/mycode_simple_detector.py)**

---

#### ğŸš„ **Fast R-CNN**
> *Region-based detection with RoI pooling magic*

The evolution of object detection: propose regions, pool features, and predict classes and boxes in one efficient forward pass.

**Architecture Highlights:**
- ğŸ¯ Region of Interest (RoI) pooling
- ğŸ—ï¸ ResNet50 backbone (1024 channels)
- ğŸ”€ Dual prediction heads (classification + regression)
- âš¡ Efficient multi-object detection

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Fast__RCNN.py)**

</details>

---

### ğŸ¤– Attention Mechanisms & Transformers

<details open>
<summary><b>Click to explore attention mechanisms</b></summary>

<br>

#### âœ¨ **Multi-Head Attention**
> *The revolutionary mechanism that changed NLP forever*

Multi-head attention allows models to attend to different representation subspaces simultaneouslyâ€”the core innovation behind Transformers that dethroned RNNs.

**What makes it special:**
- ğŸ‘ï¸ Multiple attention heads working in parallel
- ğŸ”„ Learns different relationships simultaneously
- ğŸ¯ Captures both local and global dependencies

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/multi-head-att.py)**

---

#### ğŸ”— **Cross-Attention**
> *When two sequences need to talk to each other*

Cross-attention enables one sequence to attend to anotherâ€”fundamental for translation, image captioning, and any encoder-decoder architecture.

**Use cases:**
- ğŸŒ Machine translation (target attends to source)
- ğŸ–¼ï¸ Image captioning (text attends to image features)
- ğŸµ Speech-to-text (transcript attends to audio)

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/cross_attention.py)**

</details>

---

### ğŸ”„ Recurrent Neural Networks

<details open>
<summary><b>Click to explore sequential models</b></summary>

<br>

#### ğŸ“ **Simple RNN**
> *The foundation of sequential learning*

Before Transformers dominated, RNNs were the go-to architecture for sequential data. Understanding RNNs illuminates why attention mechanisms were such a breakthrough.

**Core concepts:**
- ğŸ”„ Hidden state propagation through time
- ğŸ“ˆ Sequential data processing
- ğŸ§  Memory across time steps

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Simple_RNN_Pyton.py)**

</details>

---

## ğŸ—ºï¸ Learning Roadmap

```mermaid
graph TD
    A[Start: Basic Metrics] --> B[IoU Implementation]
    B --> C[Non-Maximum Suppression]
    C --> D[Mean Average Precision]
    D --> E[Object Detection]
    E --> F[Multi-Class Detector]
    F --> G[Fast R-CNN]
    
    H[Sequence Models] --> I[Simple RNN]
    
    J[Attention Revolution] --> K[Multi-Head Attention]
    K --> L[Cross-Attention]
    
    style A fill:#e1f5ff
    style E fill:#fff4e1
    style J fill:#ffe1f5
```

**Suggested Learning Path:**
1. ğŸ¯ Start with **IoU** and **NMS** to understand detection fundamentals
2. ğŸ“Š Progress to **mAP** for evaluation metrics
3. ğŸ¨ Build your first detector with **Multi-Class Object Detector**
4. ğŸš„ Level up to region-based detection with **Fast R-CNN**
5. ğŸ”„ Explore sequential processing with **Simple RNN**
6. âœ¨ Dive into modern architectures with **Multi-Head Attention**
7. ğŸ”— Master encoder-decoder patterns with **Cross-Attention**

---

## ğŸ› ï¸ Tech Stack

<div align="center">

![Python](https://img.shields.io/badge/Python-3776AB?style=for-the-badge&logo=python&logoColor=white)
![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)
![NumPy](https://img.shields.io/badge/NumPy-013243?style=for-the-badge&logo=numpy&logoColor=white)

</div>

---

## ğŸš€ Getting Started

```bash
# Clone this repository
git clone https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch.git

# Navigate to the directory
cd AI-Concepts-From-Scratch

# Each implementation is self-contained and documented
# Pick any concept and start learning!
```

---

## ğŸŒŸ What Makes This Different?

| Feature | This Repo | Typical Tutorials |
|---------|-----------|-------------------|
| **Depth** | Mathematical foundations | Surface-level API calls |
| **Clarity** | Detailed inline comments | Minimal explanation |
| **Practicality** | Production-ready patterns | Toy examples |
| **Progression** | Structured learning path | Random collection |

---

## ğŸ¤ Contributing

Contributions are not just welcomeâ€”they're encouraged! Whether it's:

- ğŸ› Bug fixes
- ğŸ“ Documentation improvements
- âœ¨ New algorithm implementations
- ğŸ’¡ Optimization suggestions

**Steps to contribute:**
1. Fork the repository
2. Create your feature branch (`git checkout -b feature/AmazingFeature`)
3. Commit your changes (`git commit -m 'Add some AmazingFeature'`)
4. Push to the branch (`git push origin feature/AmazingFeature`)
5. Open a Pull Request

---

## ğŸ“š Resources & References

**Books:**
- ğŸ“– *Deep Learning* by Goodfellow, Bengio, and Courville
- ğŸ“– *Pattern Recognition and Machine Learning* by Christopher Bishop

**Papers:**
- ğŸ“„ Fast R-CNN (Girshick, 2015)
- ğŸ“„ Attention Is All You Need (Vaswani et al., 2017)

---

## ğŸ“¬ Connect & Discuss

Have questions? Want to discuss implementations? Found a bug?

- ğŸ’¬ Open an [Issue](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/issues)
- â­ Star this repo if you find it helpful
- ğŸ”„ Share with others who want to understand AI deeply

---

<div align="center">

### ğŸ’« *"Understanding is the foundation of innovation"*

**Built with ğŸ§  by passionate AI learners**

[â¬† Back to Top](#-ai-concepts-from-scratch)

---

**If this repository helped you understand AI better, consider giving it a â­!**

</div>

<div align="center">

# ğŸ§  AI Concepts From Scratch

### *Demystifying Artificial Intelligence, One Algorithm at a Time*

[![Made with Python](https://img.shields.io/badge/Made%20with-Python-3776AB?style=for-the-badge&logo=python&logoColor=white)](https://python.org)
[![PyTorch](https://img.shields.io/badge/PyTorch-EE4C2C?style=for-the-badge&logo=pytorch&logoColor=white)](https://pytorch.org)
[![License](https://img.shields.io/badge/License-MIT-green?style=for-the-badge)](LICENSE)

*Dive deep into the mathematical elegance and computational beauty of AI algorithms by building them from the ground up.*

[Explore Implementations](#-implemented-concepts) â€¢ [Why From Scratch?](#-why-from-scratch) â€¢ [Get Started](#-getting-started)

---

</div>

## ğŸŒŸ About This Repository

Welcome to a journey through the foundations of artificial intelligence! This repository is a curated collection of AI and deep learning algorithms implemented from first principles. Each implementation peels back the layers of abstraction to reveal the elegant mathematics and clever engineering that power modern AI systems.

> **Philosophy:** *"What I cannot create, I do not understand."* â€“ Richard Feynman

By rebuilding these algorithms without relying on high-level abstractions, we gain intuition that no amount of reading can provide. This is learning by doing, understanding by building.

## ğŸ’¡ Why From Scratch?

<table>
<tr>
<td width="50%">

### ğŸ”¬ **Deep Understanding**
Move beyond surface-level knowledge. When you implement backpropagation by hand or derive attention mechanisms from scratch, the mathematics becomes intuition.

### ğŸ› **Master Debugging**
Know exactly what's happening at every step. Identify bottlenecks, understand edge cases, and optimize with confidence.

</td>
<td width="50%">

### ğŸ¯ **Interview Excellence**
Stand out in technical interviews. Demonstrate not just what algorithms do, but *how* and *why* they work.

### ğŸš€ **Innovation Ready**
Understanding fundamentals is the foundation for innovation. You can't improve what you don't understand.

</td>
</tr>
</table>

---

## ğŸ”¥ Implemented Concepts

### ğŸ¯ Computer Vision & Object Detection

<details open>
<summary><b>Click to explore vision algorithms</b></summary>

<br>

#### ğŸ“ **Intersection over Union (IoU)**
> *The fundamental metric for measuring bounding box overlap*

IoU quantifies how well two bounding boxes alignâ€”essential for evaluating object detection models and implementing NMS.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/IOU_from_scarth/blob/main/IOU%20from%20scratsh.py)**

---

#### ğŸ­ **Non-Maximum Suppression (NMS)**
> *Eliminating redundant detections with elegance*

When a detector fires multiple times for the same object, NMS intelligently selects the best prediction and suppresses the rest.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/IOU_from_scarth/blob/main/Non%20Max%20Suppression.py)**

---

#### ğŸ“Š **Mean Average Precision (mAP)**
> *The gold standard for detection evaluation*

mAP combines precision and recall across all classes and IoU thresholds, providing a single metric that captures model performance comprehensively.

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Mean%20Average%20Precision.py)**

---

#### ğŸ¨ **Multi-Class Object Detector**
> *End-to-end detection with ResNet50 backbone*

A complete detection pipeline combining classification and localization. Features dual-head architecture with CrossEntropyLoss for classes and MSELoss for bounding boxes.

**Key Features:**
- ğŸ—ï¸ ResNet50 feature extraction
- ğŸ¯ Multi-class classification head
- ğŸ“¦ Bounding box regression head
- âš¡ Efficient single-stage detection

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/mycode_simple_detector.py)**

---

#### ğŸš„ **Fast R-CNN**
> *Region-based detection with RoI pooling magic*

The evolution of object detection: propose regions, pool features, and predict classes and boxes in one efficient forward pass.

**Architecture Highlights:**
- ğŸ¯ Region of Interest (RoI) pooling
- ğŸ—ï¸ ResNet50 backbone (1024 channels)
- ğŸ”€ Dual prediction heads (classification + regression)
- âš¡ Efficient multi-object detection

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Fast__RCNN.py)**

</details>

---

### ğŸ¤– Attention Mechanisms & Transformers

<details open>
<summary><b>Click to explore attention mechanisms</b></summary>

<br>

#### âœ¨ **Multi-Head Attention**
> *The revolutionary mechanism that changed NLP forever*

Multi-head attention allows models to attend to different representation subspaces simultaneouslyâ€”the core innovation behind Transformers that dethroned RNNs.

**What makes it special:**
- ğŸ‘ï¸ Multiple attention heads working in parallel
- ğŸ”„ Learns different relationships simultaneously
- ğŸ¯ Captures both local and global dependencies

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/multi-head-att.py)**

---

#### ğŸ”— **Cross-Attention**
> *When two sequences need to talk to each other*

Cross-attention enables one sequence to attend to anotherâ€”fundamental for translation, image captioning, and any encoder-decoder architecture.

**Use cases:**
- ğŸŒ Machine translation (target attends to source)
- ğŸ–¼ï¸ Image captioning (text attends to image features)
- ğŸµ Speech-to-text (transcript attends to audio)

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/cross_attention.py)**

</details>

---

### ğŸ”„ Recurrent Neural Networks

<details open>
<summary><b>Click to explore sequential models</b></summary>

<br>

#### ğŸ“ **Simple RNN**
> *The foundation of sequential learning*

Before Transformers dominated, RNNs were the go-to architecture for sequential data. Understanding RNNs illuminates why attention mechanisms were such a breakthrough.

**Core concepts:**
- ğŸ”„ Hidden state propagation through time
- ğŸ“ˆ Sequential data processing
- ğŸ§  Memory across time steps

**[ğŸ” View Implementation](https://github.com/mohamed-ehab415/AI-Concepts-From-Scratch/blob/main/Simple_RNN_Pyton.py)**

</details>

---


</div>
